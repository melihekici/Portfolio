{"ast":null,"code":"import React from'react';import styles from'./Project1.module.css';import JobScrapperImage1 from'../../assets/LinkedinJobScrapper.JPG';import JobScrapperImage2 from'../../assets/LinkedinJobScrapper2.JPG';import OutputImage from'../../assets/Python Developer.jpg';import{jsx as _jsx}from\"react/jsx-runtime\";import{jsxs as _jsxs}from\"react/jsx-runtime\";function Project1(props){function pageChangeHandler(){props.pageChanger(\"home\");};return/*#__PURE__*/_jsxs(React.Fragment,{children:[/*#__PURE__*/_jsxs(\"h1\",{children:[/*#__PURE__*/_jsx(\"img\",{alt:\"Back\",onClick:pageChangeHandler,className:styles[\"back-button\"],width:\"25rem\",src:\"https://image.flaticon.com/icons/png/512/60/60577.png\"}),\"Job Scrapper\"]}),/*#__PURE__*/_jsxs(\"div\",{classname:styles['project-div'],children:[/*#__PURE__*/_jsxs(\"p\",{className:styles[\"source-code\"],children:[\"Source Code (Python): \",/*#__PURE__*/_jsx(\"a\",{rel:\"noreferrer\",target:\"_blank\",href:\"https://github.com/melihekici/LinkedInJobScrapper\",children:\"github.com/melihekici\"})]}),/*#__PURE__*/_jsxs(\"p\",{className:styles[\"source-code\"],children:[\"Source Code (Java): \",/*#__PURE__*/_jsx(\"a\",{rel:\"noreferrer\",target:\"_blank\",href:\"https://github.com/melihekici/-LinkedInJobScrapper-Java-\",children:\"github.com/melihekici\"})]}),/*#__PURE__*/_jsx(\"hr\",{}),/*#__PURE__*/_jsx(\"img\",{alt:\"Job Scrapper\",className:styles[\"project-paragraph-image\"],src:JobScrapperImage1}),/*#__PURE__*/_jsxs(\"p\",{className:styles[\"project-paragraph\"],children:[\"This app has been written in Python using Selenium.\",/*#__PURE__*/_jsx(\"br\",{}),\" It has a basic tkinter GUI which will ask you the Job to be searched and the location.\"]}),/*#__PURE__*/_jsx(\"hr\",{}),/*#__PURE__*/_jsx(\"img\",{alt:\"Python-Selenium\",class:\"project-paragraph-image\",src:\"https://static.javatpoint.com/tutorial/selenium-python/images/selenium-python.png\"}),/*#__PURE__*/_jsxs(\"p\",{class:\"project-paragraph\",children:[\"After you start scraping, a Chrome driver window opens in headless mode(invisible) and searches for the jobs in linkedin using the search term and location specified.\",/*#__PURE__*/_jsx(\"br\",{}),\"It will scroll down until it reaches at the end of the page and will create an array containing all of the job urls.\"]}),/*#__PURE__*/_jsx(\"hr\",{}),/*#__PURE__*/_jsx(\"img\",{alt:\"Requests\",class:\"project-paragraph-image\",src:\"https://miro.medium.com/max/700/1*ZSmnw481OjgPRtDR40gQoA.png\"}),/*#__PURE__*/_jsxs(\"p\",{class:\"project-paragraph\",children:[\"After getting all the urls, the Chrome driver will close itself and all of the job lists will be scraped one by one using requests package.\",/*#__PURE__*/_jsx(\"br\",{}),\"For each job url, the job description content will be extracted from page source.\",/*#__PURE__*/_jsx(\"br\",{}),\"Tech skills are predefined in a dictionary. For some skills, some aliases are also taken into consideration(example: css and css3 will map to same key value in the dictionary)\",/*#__PURE__*/_jsx(\"br\",{}),\"Each skill is searched inside of the job description one by one and if found the count is incremented by one.\",/*#__PURE__*/_jsx(\"br\",{}),\"At the end, we get a dictionary which shows each skill as the key and the number of job postings mentioning that skill as value.\"]}),/*#__PURE__*/_jsx(\"hr\",{}),/*#__PURE__*/_jsx(\"img\",{alt:\"output\",style:{width:\"755px\"},className:styles[\"project-paragraph-image\"],src:JobScrapperImage2}),/*#__PURE__*/_jsxs(\"p\",{class:\"project-paragraph\",children:[\"On completion, a word cloud will be created, opened and be saved as \",\"{Search Term}\",\".jpg\"]}),/*#__PURE__*/_jsx(\"img\",{alt:\"output\",style:{width:\"755px\",border:\"solid\",borderWidth:\"thin\",marginBottom:\"5rem\"},className:styles[\"project-paragraph-image\"],src:OutputImage})]})]});};export default Project1;","map":{"version":3,"sources":["/home/canavar/Desktop/react/tutorial/portfolio/src/components/Project1/Project1.js"],"names":["React","styles","JobScrapperImage1","JobScrapperImage2","OutputImage","Project1","props","pageChangeHandler","pageChanger","width","border","borderWidth","marginBottom"],"mappings":"AAAA,MAAOA,CAAAA,KAAP,KAAkB,OAAlB,CAEA,MAAOC,CAAAA,MAAP,KAAmB,uBAAnB,CAEA,MAAOC,CAAAA,iBAAP,KAA8B,sCAA9B,CACA,MAAOC,CAAAA,iBAAP,KAA8B,uCAA9B,CACA,MAAOC,CAAAA,WAAP,KAAwB,mCAAxB,C,wFAEA,QAASC,CAAAA,QAAT,CAAkBC,KAAlB,CAAyB,CAErB,QAASC,CAAAA,iBAAT,EAA6B,CACzBD,KAAK,CAACE,WAAN,CAAkB,MAAlB,EACH,EAED,mBACI,MAAC,KAAD,CAAO,QAAP,yBACI,mCACI,YAAK,GAAG,CAAC,MAAT,CAAgB,OAAO,CAAED,iBAAzB,CAA4C,SAAS,CAAEN,MAAM,CAAC,aAAD,CAA7D,CAA8E,KAAK,CAAC,OAApF,CAA4F,GAAG,CAAC,uDAAhG,EADJ,kBADJ,cAKI,aAAK,SAAS,CAAEA,MAAM,CAAC,aAAD,CAAtB,wBACI,WAAG,SAAS,CAAEA,MAAM,CAAC,aAAD,CAApB,iDAA2D,UAAG,GAAG,CAAC,YAAP,CAAoB,MAAM,CAAC,QAA3B,CAAoC,IAAI,CAAC,mDAAzC,mCAA3D,GADJ,cAEI,WAAG,SAAS,CAAEA,MAAM,CAAC,aAAD,CAApB,+CAAyD,UAAG,GAAG,CAAC,YAAP,CAAoB,MAAM,CAAC,QAA3B,CAAoC,IAAI,CAAC,0DAAzC,mCAAzD,GAFJ,cAGI,aAHJ,cAII,YAAK,GAAG,CAAC,cAAT,CAAwB,SAAS,CAAEA,MAAM,CAAC,yBAAD,CAAzC,CAAsE,GAAG,CAAEC,iBAA3E,EAJJ,cAKI,WAAG,SAAS,CAAED,MAAM,CAAC,mBAAD,CAApB,8EAA8F,aAA9F,6FALJ,cAMI,aANJ,cAOI,YAAK,GAAG,CAAC,iBAAT,CAA2B,KAAK,CAAC,yBAAjC,CAA2D,GAAG,CAAC,mFAA/D,EAPJ,cAQI,WAAG,KAAK,CAAC,mBAAT,iMAAmM,aAAnM,0HARJ,cASI,aATJ,cAUI,YAAK,GAAG,CAAC,UAAT,CAAoB,KAAK,CAAC,yBAA1B,CAAoD,GAAG,CAAC,8DAAxD,EAVJ,cAWI,WAAG,KAAK,CAAC,mBAAT,sKACI,aADJ,kGAEI,aAFJ,gMAGI,aAHJ,8HAII,aAJJ,sIAXJ,cAiBI,aAjBJ,cAkBI,YAAK,GAAG,CAAC,QAAT,CAAkB,KAAK,CAAE,CAACQ,KAAK,CAAE,OAAR,CAAzB,CAA2C,SAAS,CAAER,MAAM,CAAC,yBAAD,CAA5D,CAAyF,GAAG,CAAEE,iBAA9F,EAlBJ,cAmBI,WAAG,KAAK,CAAC,mBAAT,2GAnBJ,cAoBI,YAAK,GAAG,CAAC,QAAT,CAAkB,KAAK,CAAE,CAACM,KAAK,CAAE,OAAR,CAAiBC,MAAM,CAAE,OAAzB,CAAkCC,WAAW,CAAE,MAA/C,CAAuDC,YAAY,CAAE,MAArE,CAAzB,CAAuG,SAAS,CAAEX,MAAM,CAAC,yBAAD,CAAxH,CAAqJ,GAAG,CAAEG,WAA1J,EApBJ,GALJ,GADJ,CA8BH,EAED,cAAeC,CAAAA,QAAf","sourcesContent":["import React from 'react';\n\nimport styles from './Project1.module.css';\n\nimport JobScrapperImage1 from '../../assets/LinkedinJobScrapper.JPG';\nimport JobScrapperImage2 from '../../assets/LinkedinJobScrapper2.JPG';\nimport OutputImage from '../../assets/Python Developer.jpg';\n\nfunction Project1(props) {\n\n    function pageChangeHandler() {\n        props.pageChanger(\"home\");\n    };\n\n    return (\n        <React.Fragment>\n            <h1>\n                <img alt=\"Back\" onClick={pageChangeHandler} className={styles[\"back-button\"]} width=\"25rem\" src=\"https://image.flaticon.com/icons/png/512/60/60577.png\"/>\n                Job Scrapper\n            </h1>\n            <div classname={styles['project-div']}>\n                <p className={styles[\"source-code\"]}>Source Code (Python): <a rel=\"noreferrer\" target=\"_blank\" href=\"https://github.com/melihekici/LinkedInJobScrapper\">github.com/melihekici</a></p>\n                <p className={styles[\"source-code\"]}>Source Code (Java): <a rel=\"noreferrer\" target=\"_blank\" href=\"https://github.com/melihekici/-LinkedInJobScrapper-Java-\">github.com/melihekici</a></p>\n                <hr/>\n                <img alt=\"Job Scrapper\" className={styles[\"project-paragraph-image\"]} src={JobScrapperImage1}/>\n                <p className={styles[\"project-paragraph\"]}>This app has been written in Python using Selenium.<br/> It has a basic tkinter GUI which will ask you the Job to be searched and the location.</p>\n                <hr/>\n                <img alt=\"Python-Selenium\" class=\"project-paragraph-image\" src=\"https://static.javatpoint.com/tutorial/selenium-python/images/selenium-python.png\"/>\n                <p class=\"project-paragraph\">After you start scraping, a Chrome driver window opens in headless mode(invisible) and searches for the jobs in linkedin using the search term and location specified.<br/>It will scroll down until it reaches at the end of the page and will create an array containing all of the job urls.</p>\n                <hr/>\n                <img alt=\"Requests\" class=\"project-paragraph-image\" src=\"https://miro.medium.com/max/700/1*ZSmnw481OjgPRtDR40gQoA.png\"/>\n                <p class=\"project-paragraph\">After getting all the urls, the Chrome driver will close itself and all of the job lists will be scraped one by one using requests package.\n                    <br/>For each job url, the job description content will be extracted from page source.\n                    <br/>Tech skills are predefined in a dictionary. For some skills, some aliases are also taken into consideration(example: css and css3 will map to same key value in the dictionary)\n                    <br/>Each skill is searched inside of the job description one by one and if found the count is incremented by one.\n                    <br/>At the end, we get a dictionary which shows each skill as the key and the number of job postings mentioning that skill as value.\n                </p>\n                <hr/>\n                <img alt=\"output\" style={{width: \"755px\"}} className={styles[\"project-paragraph-image\"]} src={JobScrapperImage2}></img>\n                <p class=\"project-paragraph\">On completion, a word cloud will be created, opened and be saved as {`{Search Term}`}.jpg</p>\n                <img alt=\"output\" style={{width: \"755px\", border: \"solid\", borderWidth: \"thin\", marginBottom: \"5rem\"}} className={styles[\"project-paragraph-image\"]} src={OutputImage}></img>\n            </div>\n        </React.Fragment>\n    );\n};\n\nexport default Project1;\n\n\n"]},"metadata":{},"sourceType":"module"}